colors="#66aa33")
getwd()
setwd("C:/Users/akhil/OneDrive/Documents/Project 3/Netflix")
#netflix titles
netflix_titles_1=read.csv("netflix_titles.csv")
netflix_titles=read.csv("netflix_titles.csv")
#################################################################################################################################################################################################
## Text mining ####FOR GOOD TITLES NETFLIX##############################################################################################################################################################
###################################################################################################################################################################################################
netflix_titles_good <- subset(netflix_titles, typeOfPeriod == "good")
netflix_precorpus1 <- subset(netflix_titles_good,select = c(show_id,listed_in))
colnames(netflix_precorpus1) <- c("ID","TitleType")
netflix_precorpus1$TitleType <- gsub("'", "", netflix_precorpus1$TitleType) # remove apostrophes
netflix_precorpus1$TitleType <- gsub("[[:punct:]]", " ", netflix_precorpus1$TitleType)  # replace punctuation with space
netflix_precorpus1$TitleType <- gsub("[[:cntrl:]]", " ", netflix_precorpus1$TitleType)  # replace control characters with space
netflix_precorpus1$TitleType <- gsub("^[[:space:]]+", "", netflix_precorpus1$TitleType) # remove whitespace at beginning of documents
netflix_precorpus1$TitleType <- gsub("[[:space:]]+$", "", netflix_precorpus1$TitleType) # remove whitespace at end of documents
netflix_precorpus1$TitleType <- gsub("[^a-zA-Z -]", " ", netflix_precorpus1$TitleType) # allows only letters
netflix_precorpus1$TitleType <- tolower(netflix_precorpus1$TitleType)  # force to lowercase
head(netflix_precorpus1$TitleType)
library(quanteda)
netflix_dfm.simple1<- dfm(netflix_precorpus1$TitleType,
remove = stopwords("english"),
verbose=TRUE,
stem=FALSE)
topfeatures(netflix_dfm.simple1, n=50)
# create a custom dictonary
netflix_swlist1 = c("tv","movi*","show*","fi","scienc*","seri*")
netflix_dfm1<- dfm(netflix_precorpus1$TitleType,
remove = c(netflix_swlist1,stopwords("english")),
verbose=TRUE,
stem=FALSE)
topfeatures(netflix_dfm1, n=70)
netflix_dfm.stem1<- dfm(netflix_precorpus1$TitleType,
remove = c(netflix_swlist1,stopwords("english")),
verbose=TRUE,
stem=TRUE)
data.frame(topfeatures(netflix_dfm.stem1, n=50))
# create a custom dictonary
netflix_swlist1 = c("tv","movi*","show*","fi","scienc*","seri*")
netflix_dfm1<- dfm(netflix_precorpus1$TitleType,
remove = c(netflix_swlist1,stopwords("english")),
verbose=TRUE,
stem=FALSE)
topfeatures(netflix_dfm1, n=70)
#update for bigrans using tokens
netflix_toks.1<-tokens(netflix_precorpus1$TitleType)   #creates tokens
netflix_toks.2<-tokens_remove(netflix_toks.1, stopwords("english"))  #remove stopwords from tokens
netflix_toks.3 <-tokens_ngrams(netflix_toks.2, n=2) # ngram =2
netflix_dfm.ngram1<- dfm(netflix_toks.3, verbose=TRUE)
topfeatures(netflix_dfm.ngram1, n=100)
#########################
### WORD CLOUD ########
#########################
library(wordcloud)
set.seed(142)   #keeps cloud' shape fixed
netflix_freq1 <-topfeatures(netflix_dfm1, n=500)
wordcloud(names(netflix_freq1),
netflix_freq1, max.words=500,
scale=c(6, .6),
color = "#E50914")
wordcloud(names(netflix_freq1),
netflix_freq1, max.words=500,
scale=c(6, .6),
color = "#E50914")
wordcloud(names(netflix_freq1),
netflix_freq1, max.words=500,
scale=c(6, .6),
color = "#E50914")
wordcloud(names(netflix_freq1),
netflix_freq1, max.words=500,
scale=c(6, .6),
color = "#E50914")
wordcloud(names(netflix_freq1),
netflix_freq1, max.words=500,
scale=c(6, .6),
color = "#E50914")
wordcloud(names(netflix_freq1),
netflix_freq1, max.words=500,
scale=c(6, .6),
color = "#E50914")
wordcloud(names(netflix_freq1),
netflix_freq1, max.words=500,
scale=c(6, .6),
color = "#E50914")
wordcloud(names(netflix_freq1),
netflix_freq1, max.words=500,
scale=c(6, .6),
color = "#E50914")
wordcloud(names(netflix_freq1),
netflix_freq1, max.words=500,
scale=c(6, .6),
color = "#E50914")
wordcloud(names(netflix_freq1),
netflix_freq1, max.words=500,
scale=c(6, .6),
color = "#E50914")
wordcloud(names(netflix_freq1),
netflix_freq1, max.words=500,
scale=c(6, .6),
color = "#E50914")
wordcloud(names(netflix_freq1),
netflix_freq1, max.words=500,
scale=c(6, .6),
color = "#E50914")
netflix_titles_bad <- subset(netflix_titles, typeOfPeriod == "bad")
netflix_precorpus2 <- subset(netflix_titles_bad,select = c(show_id,listed_in,date_added))
colnames(netflix_precorpus2) <- c("ID","TitleType")
netflix_precorpus2$TitleType <- gsub("'", "", netflix_precorpus2$TitleType) # remove apostrophes
netflix_precorpus2$TitleType <- gsub("[[:punct:]]", " ", netflix_precorpus2$TitleType)  # replace punctuation with space
netflix_precorpus2$TitleType <- gsub("[[:cntrl:]]", " ", netflix_precorpus2$TitleType)  # replace control characters with space
netflix_precorpus2$TitleType <- gsub("^[[:space:]]+", "", netflix_precorpus2$TitleType) # remove whitespace at beginning of documents
netflix_precorpus2$TitleType <- gsub("[[:space:]]+$", "", netflix_precorpus2$TitleType) # remove whitespace at end of documents
netflix_precorpus2$TitleType <- gsub("[^a-zA-Z -]", " ", netflix_precorpus2$TitleType) # allows only letters
netflix_precorpus2$TitleType <- tolower(netflix_precorpus2$TitleType)  # force to lowercase
head(netflix_precorpus2$TitleType)
library(quanteda)
netflix_dfm.simple2<- dfm(netflix_precorpus2$TitleType,
remove = stopwords("english"),
verbose=TRUE,
stem=FALSE)
topfeatures(netflix_dfm.simple2, n=50)
# create a custom dictonary
netflix_swlist2 = c("tv","movi*","docuseri*","fi","classic","seri*","show*","featur*","talk","docuseri*","languag*","faith")
netflix_dfm2<- dfm(netflix_precorpus2$TitleType,
remove = c(netflix_swlist2,stopwords("english")),
verbose=TRUE,
stem=FALSE)
topfeatures(netflix_dfm2, n=70)
#########################
### WORD CLOUD ########
#########################
library(wordcloud)
set.seed(142)   #keeps cloud' shape fixed
netflix_freq2 <-topfeatures(netflix_dfm2, n=500)
wordcloud(names(netflix_freq2),
netflix_freq2, max.words=500,
scale=c(6, .6),
color = "#E50914")
wordcloud(names(netflix_freq2),
netflix_freq2, max.words=500,
scale=c(6, .6),
color = "#E50914")
wordcloud(names(netflix_freq2),
netflix_freq2, max.words=500,
scale=c(6, .6),
color = "#E50914")
getwd()
setwd("C:/Users/akhil/OneDrive/Documents/Project 3/Disney Plus")
#disney_plus titles
disney_plus_titles_1=read.csv("disney_plus_titles.csv")
disney_plus_titles=read.csv("disney_plus_titles.csv")
summary(as.factor(disney_plus_titles$typeOfPeriod))
#################################################################################################################################################################################################
## Text mining ####FOR GOOD TITLES disney_plus##############################################################################################################################################################
###################################################################################################################################################################################################
disney_plus_titles_good <- subset(disney_plus_titles, typeOfPeriod == "good")
disney_plus_precorpus1 <- subset(disney_plus_titles_good,select = c(show_id,listed_in))
colnames(disney_plus_precorpus1) <- c("ID","TitleType")
disney_plus_precorpus1$TitleType <- gsub("'", "", disney_plus_precorpus1$TitleType) # remove apostrophes
disney_plus_precorpus1$TitleType <- gsub("[[:punct:]]", " ", disney_plus_precorpus1$TitleType)  # replace punctuation with space
disney_plus_precorpus1$TitleType <- gsub("[[:cntrl:]]", " ", disney_plus_precorpus1$TitleType)  # replace control characters with space
disney_plus_precorpus1$TitleType <- gsub("^[[:space:]]+", "", disney_plus_precorpus1$TitleType) # remove whitespace at beginning of documents
disney_plus_precorpus1$TitleType <- gsub("[[:space:]]+$", "", disney_plus_precorpus1$TitleType) # remove whitespace at end of documents
disney_plus_precorpus1$TitleType <- gsub("[^a-zA-Z -]", " ", disney_plus_precorpus1$TitleType) # allows only letters
disney_plus_precorpus1$TitleType <- tolower(disney_plus_precorpus1$TitleType)  # force to lowercase
head(disney_plus_precorpus1$TitleType)
library(quanteda)
disney_plus_dfm.simple1<- dfm(disney_plus_precorpus1$TitleType,
remove = stopwords("english"),
verbose=TRUE,
stem=FALSE)
topfeatures(disney_plus_dfm.simple1, n=50)
# create a custom dictonary
disney_plus_swlist1 = c("age","varieti*","show","cook","docuseri*","spi*","seri*","medic","come","espionag*","soap")
disney_plus_dfm1<- dfm(disney_plus_precorpus1$TitleType,
remove = c(disney_plus_swlist1,stopwords("english")),
verbose=TRUE,
stem=FALSE)
topfeatures(disney_plus_dfm1, n=100)
disney_plus_dfm.simple1<- dfm(disney_plus_precorpus1$TitleType,
remove = stopwords("english"),
verbose=TRUE,
stem=FALSE)
topfeatures(disney_plus_dfm.simple1, n=50)
# create a custom dictonary
disney_plus_swlist1 = c("age","varieti*","show","cook","docuseri*","spi*","seri*","medic","come","espionag*","soap")
disney_plus_dfm1<- dfm(disney_plus_precorpus1$TitleType,
remove = c(disney_plus_swlist1,stopwords("english")),
verbose=TRUE,
stem=FALSE)
topfeatures(disney_plus_dfm1, n=100)
topfeatures_good <- as.data.frame(topfeatures(disney_plus_dfm1, n=100))
write.csv(topfeatures_good,"topfeatures_gooddisney.csv")
#update for bigrans using tokens
disney_plus_toks.1<-tokens(disney_plus_precorpus1$TitleType)   #creates tokens
disney_plus_toks.2<-tokens_remove(disney_plus_toks.1, stopwords("english"))  #remove stopwords from tokens
disney_plus_toks.3 <-tokens_ngrams(disney_plus_toks.2, n=2) # ngram =2
disney_plus_dfm.ngram1<- dfm(disney_plus_toks.3, verbose=TRUE)
topfeatures(disney_plus_dfm.ngram1, n=100)
#########################
### WORD CLOUD ########
#########################
library(wordcloud)
set.seed(142)   #keeps cloud' shape fixed
disney_plus_freq1 <-topfeatures(disney_plus_dfm1, n=500)
wordcloud(names(disney_plus_freq1),
disney_plus_freq1, max.words=500,
scale=c(6, .6),
colors="#153866")
disney_plus_titles_bad <- subset(disney_plus_titles, typeOfPeriod == "poor")
disney_plus_precorpus2 <- subset(disney_plus_titles_bad,select = c(show_id,listed_in))
colnames(disney_plus_precorpus2) <- c("ID","TitleType")
disney_plus_precorpus2$TitleType <- gsub("'", "", disney_plus_precorpus2$TitleType) # remove apostrophes
disney_plus_precorpus2$TitleType <- gsub("[[:punct:]]", " ", disney_plus_precorpus2$TitleType)  # replace punctuation with space
disney_plus_precorpus2$TitleType <- gsub("[[:cntrl:]]", " ", disney_plus_precorpus2$TitleType)  # replace control characters with space
disney_plus_precorpus2$TitleType <- gsub("^[[:space:]]+", "", disney_plus_precorpus2$TitleType) # remove whitespace at beginning of documents
disney_plus_precorpus2$TitleType <- gsub("[[:space:]]+$", "", disney_plus_precorpus2$TitleType) # remove whitespace at end of documents
disney_plus_precorpus2$TitleType <- gsub("[^a-zA-Z -]", " ", disney_plus_precorpus2$TitleType) # allows only letters
disney_plus_precorpus2$TitleType <- tolower(disney_plus_precorpus2$TitleType)  # force to lowercase
head(disney_plus_precorpus2$TitleType)
library(quanteda)
disney_plus_dfm.simple2<- dfm(disney_plus_precorpus2$TitleType,
remove = stopwords("english"),
verbose=TRUE,
stem=FALSE)
topfeatures(disney_plus_dfm.simple2, n=50)
# create a custom dictonary
disney_plus_swlist2 = c("science","varieti*","spi*","show*","surviv*","film*","movi*","seri*","soap*","polic*","cop*","age","docuseri*")
disney_plus_dfm2<- dfm(disney_plus_precorpus2$TitleType,
remove = c(disney_plus_swlist2,stopwords("english")),
verbose=TRUE,
stem=FALSE)
topfeatures(disney_plus_dfm2, n=70)
disney_plus_titles_bad <- subset(disney_plus_titles, typeOfPeriod == "poor")
disney_plus_precorpus2 <- subset(disney_plus_titles_bad,select = c(show_id,listed_in))
colnames(disney_plus_precorpus2) <- c("ID","TitleType")
disney_plus_precorpus2$TitleType <- gsub("'", "", disney_plus_precorpus2$TitleType) # remove apostrophes
disney_plus_precorpus2$TitleType <- gsub("[[:punct:]]", " ", disney_plus_precorpus2$TitleType)  # replace punctuation with space
disney_plus_precorpus2$TitleType <- gsub("[[:cntrl:]]", " ", disney_plus_precorpus2$TitleType)  # replace control characters with space
disney_plus_precorpus2$TitleType <- gsub("^[[:space:]]+", "", disney_plus_precorpus2$TitleType) # remove whitespace at beginning of documents
disney_plus_precorpus2$TitleType <- gsub("[[:space:]]+$", "", disney_plus_precorpus2$TitleType) # remove whitespace at end of documents
disney_plus_precorpus2$TitleType <- gsub("[^a-zA-Z -]", " ", disney_plus_precorpus2$TitleType) # allows only letters
disney_plus_precorpus2$TitleType <- tolower(disney_plus_precorpus2$TitleType)  # force to lowercase
head(disney_plus_precorpus2$TitleType)
library(quanteda)
disney_plus_dfm.simple2<- dfm(disney_plus_precorpus2$TitleType,
remove = stopwords("english"),
verbose=TRUE,
stem=FALSE)
topfeatures(disney_plus_dfm.simple2, n=50)
# create a custom dictonary
disney_plus_swlist2 = c("science","varieti*","spi*","show*","surviv*","film*","movi*","seri*","soap*","polic*","cop*","age","docuseri*")
disney_plus_dfm2<- dfm(disney_plus_precorpus2$TitleType,
remove = c(disney_plus_swlist2,stopwords("english")),
verbose=TRUE,
stem=FALSE)
topfeatures(disney_plus_dfm2, n=70)
topfeatures_bad <- as.data.frame(topfeatures(disney_plus_dfm2, n=100))
write.csv(topfeatures_bad,"topfeatures_baddisney.csv")
#update for bigrans using tokens
disney_plus_toks2.1<-tokens(disney_plus_precorpus2$TitleType)   #creates tokens
disney_plus_toks2.2<-tokens_remove(disney_plus_toks2.1, stopwords("english"))  #remove stopwords from tokens
disney_plus_toks2.3 <-tokens_ngrams(disney_plus_toks2.2, n=2) # ngram =2
disney_plus_dfm.ngram2<- dfm(disney_plus_toks2.3, verbose=TRUE)
topfeatures(disney_plus_dfm.ngram2, n=100)
#########################
### WORD CLOUD ########
#########################
library(wordcloud)
set.seed(142)   #keeps cloud' shape fixed
disney_plus_freq2 <-topfeatures(disney_plus_dfm2, n=500)
wordcloud(names(disney_plus_freq2),
disney_plus_freq2, max.words=500,
scale=c(6, .6),
colors="#153866")
getwd()
setwd("C:/Users/akhil/OneDrive/Documents/Project 3/Netflix")
#netflix titles
netflix_titles_1=read.csv("netflix_titles.csv")
netflix_titles=read.csv("netflix_titles.csv")
#################################################################################################################################################################################################
## Text mining ####FOR GOOD TITLES NETFLIX##############################################################################################################################################################
###################################################################################################################################################################################################
netflix_titles_good <- subset(netflix_titles, typeOfPeriod == "good")
netflix_precorpus1 <- subset(netflix_titles_good,select = c(show_id,listed_in))
colnames(netflix_precorpus1) <- c("ID","TitleType")
netflix_precorpus1$TitleType <- gsub("'", "", netflix_precorpus1$TitleType) # remove apostrophes
netflix_precorpus1$TitleType <- gsub("[[:punct:]]", " ", netflix_precorpus1$TitleType)  # replace punctuation with space
netflix_precorpus1$TitleType <- gsub("[[:cntrl:]]", " ", netflix_precorpus1$TitleType)  # replace control characters with space
netflix_precorpus1$TitleType <- gsub("^[[:space:]]+", "", netflix_precorpus1$TitleType) # remove whitespace at beginning of documents
netflix_precorpus1$TitleType <- gsub("[[:space:]]+$", "", netflix_precorpus1$TitleType) # remove whitespace at end of documents
netflix_precorpus1$TitleType <- gsub("[^a-zA-Z -]", " ", netflix_precorpus1$TitleType) # allows only letters
netflix_precorpus1$TitleType <- tolower(netflix_precorpus1$TitleType)  # force to lowercase
head(netflix_precorpus1$TitleType)
library(quanteda)
netflix_dfm.simple1<- dfm(netflix_precorpus1$TitleType,
remove = stopwords("english"),
verbose=TRUE,
stem=FALSE)
topfeatures(netflix_dfm.simple1, n=50)
# create a custom dictonary
netflix_swlist1 = c("tv","movi*","show*","fi","scienc*","seri*")
netflix_dfm1<- dfm(netflix_precorpus1$TitleType,
remove = c(netflix_swlist1,stopwords("english")),
verbose=TRUE,
stem=FALSE)
topfeatures(netflix_dfm1, n=70)
topfeatures_goodnf <- as.data.frame(topfeatures(netflix_dfm1, n=100))
write.csv(topfeatures_goodnf,"topfeatures_goodnetflix.csv")
#update for bigrans using tokens
netflix_toks.1<-tokens(netflix_precorpus1$TitleType)   #creates tokens
netflix_toks.2<-tokens_remove(netflix_toks.1, stopwords("english"))  #remove stopwords from tokens
netflix_toks.3 <-tokens_ngrams(netflix_toks.2, n=2) # ngram =2
netflix_dfm.ngram1<- dfm(netflix_toks.3, verbose=TRUE)
topfeatures(netflix_dfm.ngram1, n=100)
#########################
### WORD CLOUD ########
#########################
library(wordcloud)
set.seed(142)   #keeps cloud' shape fixed
netflix_freq1 <-topfeatures(netflix_dfm1, n=500)
wordcloud(names(netflix_freq1),
netflix_freq1, max.words=500,
scale=c(6, .6),
color = "#E50914")
#################################################################################################################################################################################################
## Text mining ####For BAD Titles netflix##############################################################################################################################################################
###################################################################################################################################################################################################
netflix_titles_bad <- subset(netflix_titles, typeOfPeriod == "bad")
netflix_precorpus2 <- subset(netflix_titles_bad,select = c(show_id,listed_in,date_added))
colnames(netflix_precorpus2) <- c("ID","TitleType")
netflix_precorpus2$TitleType <- gsub("'", "", netflix_precorpus2$TitleType) # remove apostrophes
netflix_precorpus2$TitleType <- gsub("[[:punct:]]", " ", netflix_precorpus2$TitleType)  # replace punctuation with space
netflix_precorpus2$TitleType <- gsub("[[:cntrl:]]", " ", netflix_precorpus2$TitleType)  # replace control characters with space
netflix_precorpus2$TitleType <- gsub("^[[:space:]]+", "", netflix_precorpus2$TitleType) # remove whitespace at beginning of documents
netflix_precorpus2$TitleType <- gsub("[[:space:]]+$", "", netflix_precorpus2$TitleType) # remove whitespace at end of documents
netflix_precorpus2$TitleType <- gsub("[^a-zA-Z -]", " ", netflix_precorpus2$TitleType) # allows only letters
netflix_precorpus2$TitleType <- tolower(netflix_precorpus2$TitleType)  # force to lowercase
head(netflix_precorpus2$TitleType)
library(quanteda)
netflix_dfm.simple2<- dfm(netflix_precorpus2$TitleType,
remove = stopwords("english"),
verbose=TRUE,
stem=FALSE)
topfeatures(netflix_dfm.simple2, n=50)
# create a custom dictonary
netflix_swlist2 = c("tv","movi*","docuseri*","fi","classic","seri*","show*","featur*","talk","docuseri*","languag*","faith")
netflix_dfm2<- dfm(netflix_precorpus2$TitleType,
remove = c(netflix_swlist2,stopwords("english")),
verbose=TRUE,
stem=FALSE)
topfeatures(netflix_dfm2, n=70)
topfeatures_badnf <- as.data.frame(topfeatures(netflix_dfm2, n=100))
write.csv(topfeatures_badnf,"topfeatures_badnetflix.csv")
#update for bigrans using tokens
netflix_toks2.1<-tokens(netflix_precorpus2$TitleType)   #creates tokens
netflix_toks2.2<-tokens_remove(netflix_toks2.1, stopwords("english"))  #remove stopwords from tokens
netflix_toks2.3 <-tokens_ngrams(netflix_toks2.2, n=2) # ngram =2
netflix_dfm.ngram2<- dfm(netflix_toks2.3, verbose=TRUE)
topfeatures(netflix_dfm.ngram2, n=100)
#########################
### WORD CLOUD ########
#########################
library(wordcloud)
set.seed(142)   #keeps cloud' shape fixed
netflix_freq2 <-topfeatures(netflix_dfm2, n=500)
wordcloud(names(netflix_freq2),
netflix_freq2, max.words=500,
scale=c(6, .6),
color = "#E50914")
getwd()
setwd("C:/Users/akhil/OneDrive/Documents/Project 3/Hulu/hulu_titles_new")
#hulu titles
hulu_titles_1=read.csv("hulu_titles.csv")
hulu_titles=read.csv("hulu_titles.csv")
#################################################################################################################################################################################################
## Text mining ####For GOOD Titles HULU##############################################################################################################################################################
###################################################################################################################################################################################################
hulu_titles_good <- subset(hulu_titles, typeOfPeriod == "good")
hulu_precorpus1 <- subset(hulu_titles_good,select = c(show_id,listed_in))
colnames(hulu_precorpus1) <- c("ID","TitleType")
hulu_precorpus1$TitleType <- gsub("'", "", hulu_precorpus1$TitleType) # remove apostrophes
hulu_precorpus1$TitleType <- gsub("[[:punct:]]", " ", hulu_precorpus1$TitleType)  # replace punctuation with space
hulu_precorpus1$TitleType <- gsub("[[:cntrl:]]", " ", hulu_precorpus1$TitleType)  # replace control characters with space
hulu_precorpus1$TitleType <- gsub("^[[:space:]]+", "", hulu_precorpus1$TitleType) # remove whitespace at beginning of documents
hulu_precorpus1$TitleType <- gsub("[[:space:]]+$", "", hulu_precorpus1$TitleType) # remove whitespace at end of documents
hulu_precorpus1$TitleType <- gsub("[^a-zA-Z -]", " ", hulu_precorpus1$TitleType) # allows only letters
hulu_precorpus1$TitleType <- tolower(hulu_precorpus1$TitleType)  # force to lowercase
head(hulu_precorpus1$TitleType)
library(quanteda)
hulu_dfm.simple1<- dfm(hulu_precorpus1$TitleType,
remove = stopwords("english"),
verbose=TRUE,
stem=FALSE)
topfeatures(hulu_dfm.simple1, n=50)
# create a custom dictonary
hulu_swlist1 = c("show","health","up*")
hulu_dfm1<- dfm(hulu_precorpus1$TitleType,
remove = hulu_swlist1,
verbose=TRUE,
stem=FALSE)
topfeatures(hulu_dfm1, n=50)
topfeatures_goodhulu <- as.data.frame(topfeatures(hulu_dfm1, n=100))
write.csv(topfeatures_goodhulu,"topfeatures_goodhulu.csv")
getwd()
setwd("C:/Users/akhil/OneDrive/Documents/Project 3/Hulu/hulu_titles_new")
#hulu titles
hulu_titles_1=read.csv("hulu_titles.csv")
hulu_titles=read.csv("hulu_titles.csv")
#################################################################################################################################################################################################
## Text mining ####For GOOD Titles HULU##############################################################################################################################################################
###################################################################################################################################################################################################
hulu_titles_good <- subset(hulu_titles, typeOfPeriod == "good")
hulu_precorpus1 <- subset(hulu_titles_good,select = c(show_id,listed_in))
colnames(hulu_precorpus1) <- c("ID","TitleType")
hulu_precorpus1$TitleType <- gsub("'", "", hulu_precorpus1$TitleType) # remove apostrophes
hulu_precorpus1$TitleType <- gsub("[[:punct:]]", " ", hulu_precorpus1$TitleType)  # replace punctuation with space
hulu_precorpus1$TitleType <- gsub("[[:cntrl:]]", " ", hulu_precorpus1$TitleType)  # replace control characters with space
hulu_precorpus1$TitleType <- gsub("^[[:space:]]+", "", hulu_precorpus1$TitleType) # remove whitespace at beginning of documents
hulu_precorpus1$TitleType <- gsub("[[:space:]]+$", "", hulu_precorpus1$TitleType) # remove whitespace at end of documents
hulu_precorpus1$TitleType <- gsub("[^a-zA-Z -]", " ", hulu_precorpus1$TitleType) # allows only letters
hulu_precorpus1$TitleType <- tolower(hulu_precorpus1$TitleType)  # force to lowercase
head(hulu_precorpus1$TitleType)
library(quanteda)
hulu_dfm.simple1<- dfm(hulu_precorpus1$TitleType,
remove = stopwords("english"),
verbose=TRUE,
stem=FALSE)
topfeatures(hulu_dfm.simple1, n=50)
# create a custom dictonary
hulu_swlist1 = c("show","health","up*")
hulu_dfm1<- dfm(hulu_precorpus1$TitleType,
remove = hulu_swlist1,
verbose=TRUE,
stem=FALSE)
topfeatures(hulu_dfm1, n=50)
topfeatures_goodhulu <- as.data.frame(topfeatures(hulu_dfm1, n=100))
write.csv(topfeatures_goodhulu,"topfeatures_goodhulu.csv")
#update for bigrans using tokens
hulu_toks.1<-tokens(hulu_precorpus1$TitleType)   #creates tokens
hulu_toks.2<-tokens_remove(hulu_toks.1, stopwords("english"))  #remove stopwords from tokens
hulu_toks.3 <-tokens_ngrams(hulu_toks.2, n=2) # ngram =2
hulu_dfm.ngram1<- dfm(hulu_toks.3, verbose=TRUE)
topfeatures(hulu_dfm.ngram1, n=100)
#########################
### WORD CLOUD ########
#########################
library(wordcloud)
set.seed(142)   #keeps cloud' shape fixed
hulu_freq1 <-topfeatures(hulu_dfm1, n=500)
wordcloud(names(hulu_freq1),
hulu_freq1, max.words=500,
scale=c(6,0.6),
colors="#66aa33")
#################################################################################################################################################################################################
## Text mining ####For BAD Titles HULU##############################################################################################################################################################
###################################################################################################################################################################################################
hulu_titles_bad <- subset(hulu_titles, typeOfPeriod == "poor")
hulu_precorpus2 <- subset(hulu_titles_bad,select = c(show_id,listed_in,date_added))
colnames(hulu_precorpus2) <- c("ID","TitleType")
hulu_precorpus2$TitleType <- gsub("'", "", hulu_precorpus2$TitleType) # remove apostrophes
hulu_precorpus2$TitleType <- gsub("[[:punct:]]", " ", hulu_precorpus2$TitleType)  # replace punctuation with space
hulu_precorpus2$TitleType <- gsub("[[:cntrl:]]", " ", hulu_precorpus2$TitleType)  # replace control characters with space
hulu_precorpus2$TitleType <- gsub("^[[:space:]]+", "", hulu_precorpus2$TitleType) # remove whitespace at beginning of documents
hulu_precorpus2$TitleType <- gsub("[[:space:]]+$", "", hulu_precorpus2$TitleType) # remove whitespace at end of documents
hulu_precorpus2$TitleType <- gsub("[^a-zA-Z -]", " ", hulu_precorpus2$TitleType) # allows only letters
hulu_precorpus2$TitleType <- tolower(hulu_precorpus2$TitleType)  # force to lowercase
head(hulu_precorpus2$TitleType)
library(quanteda)
hulu_dfm.simple2<- dfm(hulu_precorpus2$TitleType,
remove = stopwords("english"),
verbose=TRUE,
stem=FALSE)
topfeatures(hulu_dfm.simple2, n=50)
# create a custom dictonary
hulu_swlist2 = c("stori*","food","show","night","health","technolog*","sketch")
hulu_dfm2<- dfm(hulu_precorpus2$TitleType,
remove = c(hulu_swlist2,stopwords("english")),
verbose=TRUE,
stem = FALSE)
topfeatures(hulu_dfm2, n=70)
topfeatures_badhulu <- as.data.frame(topfeatures(hulu_dfm2, n=100))
write.csv(topfeatures_badhulu,"topfeatures_badhulu.csv")
View(disney_plus_titles_1)
rm(list=ls())
getwd()
setwd("C:/Users/akhil/OneDrive/Documents/Project 3/Hulu/duration datasets")
setwd("C:/Users/akhil/OneDrive/Documents/Project 3/duration datasets")
getwd()
setwd("C:/Users/akhil/OneDrive/Documents/Project 3/duration datasets")
disney_plus_titles=read.csv("disney_plus_titles.csv")
hulu_titles=read.csv("hulu_titles_durationcorrected.csv")
View(hulu_titles)
hulu_titles=hulu_titles[-which(hulu_titles$duration==''),] #date_added
hulu_titles=hulu_titles[-which(hulu_titles$duration==''),] #duration
disney_plus_titles=disney_plu_titles[-which(disney_plus_titles$duration==''),] #duration
getwd()
setwd("C:/Users/akhil/OneDrive/Documents/Project 3/duration datasets")
disney_plus_titles=read.csv("disney_plus_titles.csv")
hulu_titles=read.csv("hulu_titles_durationcorrected.csv")
hulu_titles=hulu_titles[-which(hulu_titles$duration==''),] #duration
disney_plus_titles=disney_plu_titles[-which(disney_plus_titles$duration==''),] #duration
View(disney_plus_titles)
View(hulu_titles)
View(disney_plus_titles)
hulu_titles <- subset(hulu_titles,select=c(duration,typeofPeriod))
hulu_titles <- subset(hulu_titles,select=c(duration,typeOfPeriod))
disney_plus_titles <- subset(disney_plus_titles,select=c(duration,typeOfPeriod))
View(disney_plus_titles)
huludurationdata <- as.data.frame(table(hulu_titles))
View(huludurationdata)
